{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "13c75cc3-2ec1-402f-8a3b-7537701cb644",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Place_id Forecasted WK  Fourier_Forecast  Fourier_Fit  MLR_Forecast  \\\n",
      "0         0            76         32.215841    18.087475     30.666552   \n",
      "1         1            76          8.312250    11.504362      8.137491   \n",
      "2         2            76         12.898409    11.735514     10.890132   \n",
      "3         3            76         16.825211    15.873544     19.125181   \n",
      "4         4            76         17.103791    18.432274     21.222802   \n",
      "5         5            76         35.074038    23.889412     38.905481   \n",
      "6         6            76         26.323191    12.157969     22.850619   \n",
      "7         7            76          8.248844     8.454503      7.673241   \n",
      "8         8            76         11.703849    10.257676     13.455173   \n",
      "9         9            76          8.784046     8.723684      8.659284   \n",
      "10        0            77         16.856421    18.535317     10.878098   \n",
      "11        1            77          9.610129    11.793759      7.086301   \n",
      "12        2            77         20.613480    10.610857     14.768196   \n",
      "13        3            77         18.605795    15.980963     18.487535   \n",
      "14        4            77         18.988861    18.775936     19.931026   \n",
      "15        5            77         36.256010    21.360090     44.040562   \n",
      "16        6            77         15.808224    12.003551      8.999856   \n",
      "17        7            77         12.737735     7.918619      9.954147   \n",
      "18        8            77         11.488495    10.272620     12.351568   \n",
      "19        9            77         10.574590     8.564906      8.658772   \n",
      "\n",
      "      MLR_Fit  \n",
      "0   21.825768  \n",
      "1   12.487717  \n",
      "2   13.981973  \n",
      "3   19.156726  \n",
      "4   23.423930  \n",
      "5   33.785503  \n",
      "6   14.470449  \n",
      "7    9.701845  \n",
      "8   12.980263  \n",
      "9   10.006500  \n",
      "10  23.221301  \n",
      "11  12.989141  \n",
      "12  13.737868  \n",
      "13  19.552375  \n",
      "14  24.156850  \n",
      "15  32.082363  \n",
      "16  14.892944  \n",
      "17   9.536980  \n",
      "18  13.092115  \n",
      "19  10.042328  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.options.mode.chained_assignment = None\n",
    "# manuplation hourly data to remove minutes\n",
    "raw_data = pd.read_csv('raw_data.csv')\n",
    "time_dt = pd.to_datetime(raw_data['time'], format='%d.%m.%Y %H:%M')\n",
    "time_dt_hourbase = time_dt\n",
    "\n",
    "for i in range(0, len(time_dt)):\n",
    "    mmin = pd.Timedelta(minutes=time_dt[i].minute)\n",
    "    time_dt_hourbase[i] = time_dt[i] - mmin\n",
    "# Creating time domain for bus working hours\n",
    "data_new = raw_data.set_index(time_dt_hourbase)\n",
    "start_date = min(data_new.index)\n",
    "end_date = max(data_new.index)\n",
    "\n",
    "time_domain = pd.date_range(start=start_date, end=end_date, freq='H')\n",
    "working_time_domain = time_domain[time_domain.hour > 6]\n",
    "working_time_domain = working_time_domain[working_time_domain.hour < 17]\n",
    "working_time_domain = pd.DataFrame(data=working_time_domain, columns=['rev_time'])\n",
    "working_time_domain = working_time_domain.set_index(working_time_domain['rev_time'])\n",
    "# seperating data set for each municiplaity ID and make domain same\n",
    "\n",
    "data_new_sorted = data_new.sort_values(by=['user'], ascending=False)\n",
    "data_cleared = pd.DataFrame()\n",
    "for i in range(0, 10):\n",
    "    temp_df = data_new_sorted[data_new_sorted['place_id'] == i]\n",
    "    temp_ind = temp_df.index.duplicated(keep='first')\n",
    "    last_df = temp_df[temp_ind == False]\n",
    "    last_df = last_df.sort_index()\n",
    "    last_df = pd.concat([working_time_domain, last_df], axis=1)\n",
    "    last_df['place_id'] = last_df['place_id'].fillna(i)\n",
    "    data_cleared = data_cleared.append(last_df, ignore_index=False)\n",
    "# continiuty check\n",
    "date_freq = pd.DataFrame()\n",
    "for i in range(0, 10):\n",
    "    y = data_cleared['user'][data_cleared['place_id'] == i]\n",
    "    date_freq['place_' + str(i)] = pd.Series(working_time_domain.index.date[y.isna() == True]).value_counts()\n",
    "\n",
    "# day should be assumed completely = 20/06, 21/06, 31/07,03/08,04/08\n",
    "missing_dates = date_freq.index[date_freq['place_0'] == 10]\n",
    "# other missing data only one hour on a day\n",
    "filled_data = pd.DataFrame()\n",
    "for i in range(0, 10):\n",
    "    y = data_cleared[data_cleared['place_id'] == i]\n",
    "    for k in range(0, len(y)):\n",
    "        if y.index[k].date() in missing_dates:\n",
    "            y.time[k] = y.rev_time[k]\n",
    "            y.user[k] = (y.user[(k - 70)]+ y.user[(k -140)])*0.5\n",
    "            y.capacity[k] = y.capacity[k - 1]\n",
    "        elif pd.isna(y.user[k]) and (y.index[k].hour == 7 or y.index[k].hour == 16):\n",
    "            y.time[k] = y.rev_time[k]\n",
    "            y.user[k] = (y.user[k - 10]+y.user[k-20])*0.5\n",
    "            y.capacity[k] = y.capacity[k - 1]\n",
    "        elif pd.isna(y.user[k]):\n",
    "            y.time[k] = y.rev_time[k]\n",
    "            y.user[k] = (y.user[k - 1] + y.user[k + 1]) * 0.5\n",
    "            y.capacity[k] = y.capacity[k - 1]\n",
    "    filled_data = filled_data.append(y, ignore_index=False)\n",
    "\n",
    "\n",
    "\n",
    "results = pd.DataFrame(columns=['Place_id','Forecasted WK','Fourier_Forecast','Fourier_Fit','MLR_Forecast','MLR_Fit'])\n",
    "for wk in range (0,2):\n",
    "    for i in range(0,10):\n",
    "        N = 770\n",
    "    #Define regressors\n",
    "        t0 = np.ones((N, 1))\n",
    "        t1 =np.transpose(np.linspace(1,N,N))\n",
    "    # Harmonics of month\n",
    "    # T = 1 ay = 28 days * 10 hours\n",
    "        Tay = 28 * 10\n",
    "        om = 2 * np.pi / Tay\n",
    "        s1 = np.sin(1 * om * t1)\n",
    "        c1 = np.cos(1 * om * t1)\n",
    "        s2 = np.sin(2 * om * t1)\n",
    "        c2 = np.cos(2 * om * t1)\n",
    "        s3 = np.sin(3 * om * t1)\n",
    "        c3 = np.cos(3 * om * t1)\n",
    "    # Harmonics of 1 week % Tgun = 10 hours\n",
    "        Thafta = 10 * 7\n",
    "        omh = 2 * np.pi / Thafta\n",
    "        sh1 = np.sin(1 * omh * t1)\n",
    "        ch1 = np.cos(1 * omh * t1)\n",
    "        sh2 = np.sin(2 * omh * t1)\n",
    "        ch2 = np.cos(2 * omh * t1)\n",
    "        sh3 = np.sin(3 * omh * t1)\n",
    "        ch3 = np.cos(3 * omh * t1)\n",
    "        sh4 = np.sin(4 * omh * t1)\n",
    "        ch4 = np.cos(4 * omh * t1)\n",
    "        sh5 = np.sin(5 * omh * t1)\n",
    "        ch5 = np.cos(5 * omh * t1)\n",
    "        sh6 = np.sin(6 * omh * t1)\n",
    "        ch6 = np.cos(6 * omh * t1)\n",
    "        sh8 = np.sin(8 * omh * t1)\n",
    "        ch8 = np.cos(8 * omh * t1)\n",
    "        sh9 = np.sin(9 * omh * t1)\n",
    "        ch9 = np.cos(9 * omh * t1)\n",
    "        sh10 = np.sin(10 * omh * t1)\n",
    "        ch10 = np.cos(10 * omh * t1)\n",
    "        sh11 = np.sin(11 * omh * t1)\n",
    "        ch11 = np.cos(11 * omh * t1)\n",
    "        sh12 = np.sin(12 * omh * t1)\n",
    "        ch12 = np.cos(12 * omh * t1)\n",
    "        sh13 = np.sin(13 * omh * t1)\n",
    "        ch13 = np.cos(13 * omh * t1)\n",
    "    # Harmonics of 1 gun\n",
    "        Tgun = 10;\n",
    "        omd = 2 * np.pi / Tgun\n",
    "        sd1 = np.sin(omd * t1)\n",
    "        cd1 = np.cos(omd * t1)\n",
    "        sd2 = np.sin(2 * omd * t1)\n",
    "        cd2 = np.cos(2 * omd * t1)\n",
    "        sd3 = np.sin(3 * omd * t1)\n",
    "        cd3 = np.cos(3 * omd * t1)\n",
    "        sd4 = np.sin(4 * omd * t1)\n",
    "        cd4 = np.cos(4 * omd * t1)\n",
    "    #include modulation Fourier Coeff\n",
    "        FFour=np.column_stack((s1,c1,s2,c2,s3,c3,sh1,ch1 ,sh2,ch2,\n",
    "                          sh3, ch3, sh4, ch4, sh5, ch5, sh6, ch6, sh8, ch8,\n",
    "                          sh9, ch9, sh10, ch10, sh11, ch11, sh12, ch12, sh13, ch13,\n",
    "                          sd1, cd1, sd2, cd2, sd3, cd3, sd4, cd4,\n",
    "                          np.multiply(s1,sd1),np.multiply(c1,sd1),np.multiply(s1,cd1),np.multiply(c1,cd1),\n",
    "                          np.multiply(s1,sd2),np.multiply(c1,sd2),np.multiply(s1,cd2),np.multiply(c1,cd2),\n",
    "                          np.multiply(s1,sd3),np.multiply(c1,sd3),np.multiply(s1,cd3),np.multiply(c1,cd3),\n",
    "                          np.multiply(s1,sd4),np.multiply(c1,sd4),np.multiply(s1,cd4),np.multiply(c1,cd4),\n",
    "                          np.multiply(s2, sd1), np.multiply(c2, sd1), np.multiply(s2, cd1), np.multiply(c2, cd1),\n",
    "                          np.multiply(s2, sd2), np.multiply(c2, sd2), np.multiply(s2, cd2), np.multiply(c2, cd2),\n",
    "                          np.multiply(s2, sd3), np.multiply(c2, sd3), np.multiply(s2, cd3), np.multiply(c2, cd3),\n",
    "                          np.multiply(s2, sd4), np.multiply(c2, sd4), np.multiply(s2, cd4), np.multiply(c2, cd4),\n",
    "                          np.multiply(s3, sd1), np.multiply(c3, sd1), np.multiply(s3, cd1), np.multiply(c3, cd1),\n",
    "                          np.multiply(s3, sd2), np.multiply(c3, sd2), np.multiply(s3, cd2), np.multiply(c3, cd2),\n",
    "                          np.multiply(s3, sd3), np.multiply(c3, sd3), np.multiply(s3, cd3), np.multiply(c3, cd3),\n",
    "                          np.multiply(s3, sd4), np.multiply(c3, sd4), np.multiply(s3, cd4), np.multiply(c3, cd4)))\n",
    "\n",
    "        Ftotal =np.column_stack((t0,t1,FFour))\n",
    "        # Exclude last two weeks\n",
    "        n = 770 - 70 * (wk+1);\n",
    "        FM = Ftotal[0:n,:]\n",
    "        S = filled_data.user[filled_data['place_id'] == i]\n",
    "        S=S.to_numpy()\n",
    "        Shorizon = S[0:n] #Base Actual Data\n",
    "        Stest = S[n:n + 70]\n",
    "        FT = Ftotal[n:n + 70,:] # Fourier for test horizon\n",
    "        test_coeff=np.matmul(np.matmul(np.linalg.inv(np.matmul(np.transpose(FM),FM)),np.transpose(FM)),Shorizon)\n",
    "\n",
    "        model_fit=np.matmul(FM , test_coeff)\n",
    "        test=np.matmul(FT, test_coeff)\n",
    "        fark_fline=Stest-test\n",
    "        Mse=np.sqrt(np.matmul(np.transpose(fark_fline),fark_fline))\n",
    "        Mpe=np.mean((np.absolute(np.divide(fark_fline,Stest))))*100\n",
    "        fark_fline1=model_fit-Shorizon\n",
    "        Mpe_fit = np.mean((np.absolute(np.divide(fark_fline1, Shorizon)))) * 100\n",
    "\n",
    "\n",
    "        hours = np.tile(np.eye(10), (77, 1))\n",
    "        a = np.concatenate((np.ones((10, 1)), np.zeros((10, 6))),axis=1)\n",
    "        a = np.concatenate((a,np.roll(a, 1),np.roll(a, 2),np.roll(a, 3),np.roll(a, 4),np.roll(a, 5),np.roll(a, 6)),axis=0)\n",
    "        week = np.tile(a, (11, 1));\n",
    "        hours = hours[:,0:9];week = week[:, 0:6];\n",
    "        Freg = np.column_stack((t0, t1, hours, week));\n",
    "\n",
    "        FM = Freg[0:n,:]\n",
    "        Shorizon=S[0:n]\n",
    "        Stest = S[n:n + 70]\n",
    "        FT = Freg[n:n + 70,:]\n",
    "        test_coeff_reg=np.matmul(np.matmul(np.linalg.inv(np.matmul(np.transpose(FM),FM)),np.transpose(FM)),Shorizon)\n",
    "        model_fit_reg=np.matmul(FM , test_coeff_reg)\n",
    "        test_reg = np.matmul(FT, test_coeff_reg)\n",
    "\n",
    "        fark_fline_reg = Stest - test_reg\n",
    "        Mse_reg = np.sqrt(np.matmul(np.transpose(fark_fline_reg), fark_fline_reg))\n",
    "        Mpe_reg = np.mean((np.absolute(np.divide(fark_fline_reg, Stest)))) * 100\n",
    "        fark_fline2 = model_fit_reg - Shorizon\n",
    "        Mpe_reg_fit = np.mean((np.absolute(np.divide(fark_fline2, Shorizon)))) * 100\n",
    "\n",
    "\n",
    "        r=pd.DataFrame(data=[[i,76+wk,Mpe,Mpe_fit,Mpe_reg,Mpe_reg_fit]],columns=['Place_id','Forecasted WK','Fourier_Forecast','Fourier_Fit','MLR_Forecast','MLR_Fit'])\n",
    "        results=results.append(r,ignore_index=True)\n",
    "\n",
    "results.to_csv(r'results.csv', sep=',')\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4640b65c-4c13-4ca0-8b52-3ea41904cc27",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Explanation & comments : I developped two model both based on regression but one of them coefficients comes from Fourier Expansion \n",
    "#because if daily curves of the data are checked there is weekly periyodik cycle\n",
    "#so Fourier expansion with modulation is powerful method to modelling this kind of data. \n",
    "#Other model, multiple linear regression. When we compare results for forecast and modelling, Fourier Model's errors\n",
    "#are the lower for modelling existing data while forecast errors are quite high.\n",
    "#I didn't make any residual analysis because this just to show how I approach to any problem. \n",
    "#Also, I didn't use any algrithm packages to develop more complex model.I shared my matlab source code as well in .txt file. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
